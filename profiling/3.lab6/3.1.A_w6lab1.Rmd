---
title: "Compute Fst using sorghum and its genomic features"
author: "Jinliang Yang"
date: "2025-02-26"
output:
  html_document:
    df_print: paged
  word_document: default
---

# Syncing a fork (from the web UI)

1. Click the __Fork__ button for the Git Repo `https://github.com/jyanglab/2025-agro932-lab`
2. And then clone to your own system `git clone git@github.com:YOURID/2025-agro932-lab.git`


### If you have __Forked__ it before:

1. On GitHub, navigate to the main page of the forked repository that you want to sync with the upstream repository.
2. Select the __Fetch upstream__ drop-down.
3. Review the details about the commits from the upstream repository, then click __Fetch and merge__.
4. [How to resolve a merge conflict](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/addressing-merge-conflicts/resolving-a-merge-conflict-on-github)

---

# Simulate NGS data

### Install a software on HCC

```{bash, eval=FALSE}
cd $HOME
mkdir bin
# https://github.com/lh3/wgsim
git clone https://github.com/lh3/wgsim.git

# compilation
gcc -g -O2 -Wall -o wgsim wgsim.c -lz -lm
```

### Put the software in your searching path

```{bash, eval=FALSE}
cd $HOME
vi .bash_profile
```

Then copy the following to your `.bash_profile`

```{bash, eval=FALSE}
PATH=$PATH:~/bin/wgsim/
```



---

# NGS data simulation using `wgsim`

```
Usage:   wgsim [options] <in.ref.fa> <out.read1.fq> <out.read2.fq>

Options: -e FLOAT      base error rate [0.020]
         -d INT        outer distance between the two ends [500]
         -s INT        standard deviation [50]
         -N INT        number of read pairs [1000000]
         -1 INT        length of the first read [70]
         -2 INT        length of the second read [70]
         -r FLOAT      rate of mutations [0.0010]
         -R FLOAT      fraction of indels [0.15]
         -X FLOAT      probability an indel is extended [0.30]
         -S INT        seed for random generator [-1]
         -A FLOAT      disgard if the fraction of ambiguous 
                       bases higher than FLOAT [0.05]
         -h            haplotype mode
```

#### Type in the following command:

```{bash, eval=FALSE}
wgsim lambda.fa -e 0 -d 500 -N 5000 -1 100 -2 100 -r 0.01  \
-R 0 -X 0 -S 1234567 -h l1.read1.fq l1.read2.fq
```

---

# Reference genome

## EnsemblPlants

- Bread Wheat: [Triticum aestivum](https://plants.ensembl.org/Triticum_aestivum/Info/Index)
- Common bean: [Phaseolus vulgaris](https://plants.ensembl.org/Phaseolus_vulgaris/Info/Index)
- Domesticated sunflower: [Helianthus annuus](https://plants.ensembl.org/Helianthus_annuus/Info/Index)
- Maize: [Zea mays](https://plants.ensembl.org/Zea_mays/Info/Index?db=core)
- Soybean: [Glycine max](http://plants.ensembl.org/Glycine_max/Info/Index)
- Sorghum: [Sorghumbase.org](https://ftp.sorghumbase.org/)

--

## Important info
- Version: release-current (https://ftp.sorghumbase.org/release-current/fasta/sorghum_bicolorv5/)
- Gene annotation: GFF3

---

# Download Reference from EnsemblPlants

Maize [reference genome](https://plants.ensembl.org/Zea_mays/Info/Index)

#### Change to `largedata\lab4` folder:

```{bash, eval=FALSE}
cd largedata
mkdir sorghum
cd sorghum
```


#### Then use `wget` to download the reference genome:

```{bash, eval=FALSE}
wget https://ftp.sorghumbase.org/release-current/fasta/sorghum_bicolorv5/dna/Sorghum_bicolorv5.Sb-BTX623-REFERENCE-JGI-5.1.dna.toplevel.fa.gz

### then unzip it
gunzip Sorghum_bicolorv5.Sb-BTX623-REFERENCE-JGI-5.1.dna.toplevel.fa.gz

### then check the file with less
less Sorghum_bicolorv5.Sb-BTX623-REFERENCE-JGI-5.1.dna.toplevel.fa | grep ">"

# extracts the first 100k from chr1 of the genome 
module load seqtk

seqtk subseq Sorghum_bicolorv5.Sb-BTX623-REFERENCE-JGI-5.1.dna.toplevel.fa <(echo -e "1\t0\t100000") > chr1.fasta

```

`<(echo -e "1\t0\t100000")`: Specifies the chromosome (1) and range (1-100000).


#### next step, let's get the GFF file

```{bash, eval=FALSE}
wget https://ftp.sorghumbase.org/release-current/gff3/sorghum_bicolorv5/Sorghum_bicolorv5.Sb-BTX623-REFERENCE-JGI-5.1.gff3.gz

### then unzip it
gunzip Sorghum_bicolorv5.Sb-BTX623-REFERENCE-JGI-5.1.gff3.gz

### then check the file with less
less Sorghum_bicolorv5.Sb-BTX623-REFERENCE-JGI-5.1.gff3

```



---

# NGS data simulation using `wgsim`

## simulate 20 individals x10 coverage

```{bash, eval=FALSE}
for i in {1..20}
do
   wgsim chr1.fasta -e 0 -d 500 -N 1000000 -1 100 -2 100 -r 0.2 -S 123 -R 0 -X 0 -h l$i.read1.fq l$i.read2.fq
done
```

--


#### check how many reads

```{bash, eval=FALSE}
wc -l l1.read1.fq 
# suppose to be 4,000,000 lines = 1,000,000 reads
```

---

# A procedure to calculate $\theta$ and $F_{ST}$ values

### 1. Align the NGS reads to the reference genome
  - [bwa](https://github.com/lh3/bwa)
  - [samtools](https://github.com/samtools/samtools)


### 2. Obtain the SNP calls 
  - [bcftools](https://samtools.github.io/bcftools/bcftools.html)

### 3. Calculate the Fst value for each site and visualize the results
  - `R`

---
# A procedure to calculate $\theta$ and $F_{ST}$ values

### 1. Align the NGS reads to the reference genome


```{bash, eval=FALSE}
module load bwa samtools bcftools
# index the reference genome
bwa index chr1.fasta
```

#### Do alignment for 10 individuals using bash loop:

```{bash, eval=FALSE}
# using bwa mem to align the reads to the reference genome 
for i in {1..20}; do bwa mem chr1.fasta l$i.read1.fq l$i.read2.fq | samtools view -bSh - > l$i.bam; done
# sort
for i in *.bam; do samtools sort $i -o sorted_$i; done
# index them
for i in sorted*.bam; do samtools index $i; done
```

#### Check mapping statistics

```{bash, eval=FALSE}
samtools flagstat sorted_l1.bam
```


Letâ€™s look at an example __slurm script header__ for a job called `theta` (which is run with script `theta.sh`).

```{bash, eval=FALSE}
#!/bin/bash -l
#SBATCH -D ~projects/your-cool-project/
#SBATCH -o ~/your-cool-project/slurm-log/steve-stdout-%j.txt
#SBATCH -e ~/your-cool-project/slurm-log/steve-stderr-%j.txt
#SBATCH -J steve
#SBATCH -t 24:00:00
set -e
set -u

# insert your script here
```


---

## An Example Slurm Batch Script Header

```{bash, eval=FALSE}
#!/bin/bash -l
#SBATCH -D ~/projects/your-cool-project/
#SBATCH -o ~/your-cool-project/slurm-log/steve-stdout-%j.txt
#SBATCH -e ~/your-cool-project/slurm-log/steve-stderr-%j.txt
#SBATCH -J theta
#SBATCH -t 24:00:00
#SBATCH --mail-user=your_email_address@gmail.com
#SBATCH --mail-type=END #email if ends
#SBATCH --mail-type=FAIL #email if fails
set -e
set -u

# insert your script here
```

- `D` sets your project directory.
- `o` sets where standard output (of your batch script) goes.
- `e` sets where standard error (of your batch script) goes.
- `J` sets the job name.
- `t` sets the time limit for the job, 24:00:00 indicates 24 hours.
- `--mail`: will email you if the job is "END" or "FAIL"

---

## Let's do this in Rstudio on your labtop

insert the following into a shell script, for example `sorghum_sim.sh`

```{bash, eval=FALSE}
# module load bwa samtools
# cd largedata/lab4/

# alignment
for i in {1..20}; do bwa mem chr1.fasta l$i.read1.fq l$i.read2.fq | samtools view -bSh - > l$i.bam; done
# sort
for i in *.bam; do samtools sort $i -o sorted_$i; done
# index them
for i in sorted*.bam; do samtools index $i; done
```

--

- submit the job via `sbatch`:

```{bash, eval=FALSE}
sbatch --licenses=common --ntasks=8 --mem=60G slurm-script/sorghum_sim.sh

## check your job status
squeue | grep "YOUR USER ID"
```


---

# A procedure to calculate $\theta$ values

### 2. Obtain the SNP calls  with `samtools`


```{bash, eval=FALSE}
### index the genome assembly
samtools faidx first_chr.fa
### Run `mpileup` to generate VCF format
ls sorted_l*bam > bamlist.txt
bcftools mpileup -g -f first_chr.fa -b bamlist.txt > myraw.bcf
bcftools call myraw.bcf -cv -Ob -o snps.bcf

bcftools mpileup -Ou -f first_chr.fa -b bamlist.txt | bcftools call -mv -Ob -o snps.bcf
```

#### exact SNP information

```{bash, eval=FALSE}
### Extract allele frequency at each position
bcftools view -h snps.bcf | grep INFO
bcftools query -f '%CHROM %POS %AC\n' snps.bcf > frq.txt

bcftools query -f '%CHROM %POS %REF %ALT [\t%GT]\n' snps.bcf > geno.txt
```

- Print chromosome, position, ref allele and the first alternate allele
- %TGT: Translated genotype (e.g. C/A)
- %TAG{INT}: Curly brackets to print a subfield (e.g. INFO/TAG{1}, the indexes are 0-based)

---
# A procedure to calculate $\theta$ values

### 3. Calculate the Fst value for each site and visualize the results


```{r, eval=FALSE}
geno <- read.table("largedata/geno.txt", header=FALSE)
names(geno)[1:4] <- c("chr", "pos", "ref", "alt")


for(i in 5:24){
  # replace slash and everything after it as nothing
  geno$newcol <- gsub("/.*", "", geno[,i] )
  # extract the line name
  nm <- names(geno)[i]
  # assign name for this allele
  names(geno)[ncol(geno)] <- paste0(nm, sep="_a1")
  
  geno$newcol <- gsub(".*/", "", geno[,i] )
  names(geno)[ncol(geno)] <- paste0(nm, sep="_a2")
}
```

---

# A procedure to calculate $\theta$ values

### 3. Calculate the Fst value for each site and visualize the results

#### Compute p1, p2, p

geno[geno == "."] <- NA
```{r, eval=FALSE}
geno$p <- apply(geno[, 25:64], 1, function(x) { sum(x==0)/(sum(x==1) + sum(x=0))})
geno$p <- geno$p/10

geno$p1 <- apply(geno[, 25:46], 1, function(x) {sum(as.numeric(as.character(x)))})
geno$p1 <- geno$p1/6

geno$p2 <- apply(geno[, 47:64], 1, function(x) {sum(as.numeric(as.character(x)))})
geno$p2 <- geno$p2/4
```

Then finally,

```{r, eval=FALSE}
geno$fst <- with(geno, ((p1-p)^2 + (p2-p)^2)/(2*p*(1-p)) )
```

Output the Fst results


```{r, eval=FALSE}
write.table(geno, "cache/fst.csv", sep=",", row.names = FALSE, quote=FALSE)
```

---
# A procedure to calculate $\theta$ values

### 3. Calculate the Fst value for each site and visualize the results

#### Visualize the results on my local computer

```{r, eval=FALSE}
fst <- read.csv("cache/fst.csv")

plot(fst$pos, fst$fst, xlab="Physical position", ylab="Fst value", main="")
```



